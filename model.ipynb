{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sınıflandırıcı işlemleri\n",
    "def classifier(df):\n",
    "\n",
    "    # feature vektörünün ilk iki sutunu feature(x1), son sutunu label(y1)\n",
    "    x1 = df.iloc[:,:2]\n",
    "    y1 = df['label']\n",
    "\n",
    "    # kfold validation 5 yapıldı\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=100)\n",
    "    # sınıflandırıcı modeli logistic regression olarak ayarlı, parametreleri değişebilir\n",
    "    model_kfold = LogisticRegression(solver='lbfgs')\n",
    "    results_kfold = model_selection.cross_val_score(model_kfold, x1, y1, cv=kfold)\n",
    "    print(\"Logistic Regression Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada öznitelikler oluşturulur\n",
    "def extractFeatures(df):\n",
    "\n",
    "    # 'fDf': feature array olacak\n",
    "    fDf = pd.DataFrame()\n",
    "\n",
    "    length = [] # 1. feature: tweetteki kelime sayısı(normalize edilmemiş)\n",
    "    mention = [] # 2. feature: tweetteki mention sayısı\n",
    "\n",
    "    \n",
    "    # tweetleri sırasıyla oku\n",
    "    for text in df['tweet']:\n",
    "\n",
    "        length += [len(text.split())]\n",
    "        mention += [text.count('@')]\n",
    "\n",
    "    print(\"Toplam tweet sayısı: {}\".format(len(df)))\n",
    "    \"\"\"\n",
    "    # burada min_df değerini en az kaç tweette bulunan unigramları kullanmak için ayarla; örneğin en az 10 tweette geçen unigramlar; ngram_range ise neye bakıldığını belirler unigram için (1,1), bigram için (2,2)\n",
    "    vectorizerUnigram = CountVectorizer(ngram_range=(1, 1),min_df=10,token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\") \n",
    "    vectorizerUnigram.fit_transform(df['tweet'].values.astype('U'))     #tüm unigramları çıkarır\n",
    "    print(\"Kullanılacak unigram sayısı: {}\".format(len(vectorizerUnigram.get_feature_names())))\n",
    "    unigrams = vectorizerUnigram.get_feature_names()            #kullanılacak unigram listesi\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")    #bunu kullanarak her tweet tekrar unigramlara ayrılır ve önceden bulduklarımız içinde var mı kontrol edilir\n",
    "    \n",
    "    unigramF = np.zeros(shape=(len(df),len(unigrams)))  # tweet sayısı * unigram sayısı kadar \n",
    "    for lineIdx in range(0,len(df.tweet)):\n",
    "            vectorizer.fit_transform([str(df.tweet[lineIdx])])\n",
    "            tweetUni = vectorizer.get_feature_names()       #bir tweetteki unigramlar\n",
    "            for uni in unigrams :\n",
    "                if (uni in tweetUni):\n",
    "                    unigramF[lineIdx][unigrams.index(uni)]=1\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # aynı süreç bigram için\n",
    "    vectorizerBigram = CountVectorizer(ngram_range=(2, 2),min_df=100,token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\") \n",
    "    vectorizerBigram.fit_transform(df['tweet'].values.astype('U'))\n",
    "    print(\"Kullanılacak bigram sayısı: {}\".format(len(vectorizerBigram.get_feature_names())))\n",
    "    bigrams = vectorizerBigram.get_feature_names()\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")    \n",
    "\n",
    "    bigramF = np.zeros(shape=(len(df),len(bigrams)))  \n",
    "    for lineIdx in range(0,len(df.tweet)):\n",
    "            vectorizer.fit_transform([str(df.tweet[lineIdx])])\n",
    "            tweetBi = vectorizer.get_feature_names()       \n",
    "            for bi in bigrams :\n",
    "                if (bi in tweetBi):\n",
    "                    bigramF[lineIdx][bigrams.index(bi)]=1           \n",
    "    bigramDf = pd.DataFrame(bigramF)\n",
    "    print(bigramDf)\n",
    "\n",
    "    # featureları arraye yerleştir\n",
    "    fDf['length']=length\n",
    "    fDf['mention']=mention\n",
    "    \n",
    "    \n",
    "    # !!! kullanmak istenilen vektörü ana feature vektore ekle\n",
    "    fDf = pd.concat([fDf, bigramDf], axis=1)\n",
    "    \n",
    "\n",
    "    # train dataframeden labelları ekle\n",
    "    fDf['label']=df['subtask']\n",
    "\n",
    "    print(fDf[:10])\n",
    "\n",
    "    # hazırlanan dataframei sınıflandırıcıya ver\n",
    "    classifier(fDf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dosyasını oku ve dataframe hazırla\n",
    "def readTrainFiles():\n",
    "    columns = ['id', 'tweet', 'subtask']\n",
    "    trainFiles = []\n",
    "    ext=\".tsv\"\n",
    "    for file in glob.glob( \"./train/*\" + ext): trainFiles.append(file)\n",
    "    print(\"Train dosyasi: {}\".format(trainFiles))\n",
    "\n",
    "    dataDf = pd.read_csv(file, delimiter = '\\t', encoding = 'utf-8', names = columns, header=0)\n",
    "\n",
    "    print(\"Train dosyasi dataframe ornegi:\")\n",
    "    print(dataDf[0:10])\n",
    "\n",
    "    print(\"Dataframede OFF ve NOT yerine label olarak 1 ve 0 yazıldı :\")\n",
    "    dataDf.loc[dataDf.subtask=='OFF', 'subtask']=1\n",
    "    dataDf.loc[dataDf.subtask=='NOT', 'subtask']=0\n",
    "    print(dataDf[0:10])\n",
    "    extractFeatures(dataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train dosyasi: ['./train\\\\offenseval-tr-training-v1.tsv']\nTrain dosyasi dataframe ornegi:\n      id                                              tweet subtask\n0  20948  @USER en güzel uyuyan insan ödülü jeon jungkoo...     NOT\n1  10134  @USER Mekanı cennet olsun, saygılar sayın avuk...     NOT\n2  23457  Kızlar aranızda kas yığını beylere düşenler ol...     NOT\n3  18401  Biraz ders çalışayım. Tembellik ve uyku düşman...     NOT\n4  17525  @USER Trezeguet yerine El Sharawy daha iyi olm...     NOT\n5  11996  @USER Bence de olması gerekiyor. Hatta meslek ...     NOT\n6  38452  Mutlu gorunumlu ama daima mutsuz olanlar burda...     NOT\n7  12615  100 liraya tras oldum arkadaşım diyo ki ne kes...     NOT\n8  13520  @USER @USER @USER Reis bu ülkenin Devlet Başka...     OFF\n9  45562  Var olan, ancak düşünüldüğü kadarıyla vardır. ...     NOT\nDataframede OFF ve NOT yerine label olarak 1 ve 0 yazıldı :\n      id                                              tweet  subtask\n0  20948  @USER en güzel uyuyan insan ödülü jeon jungkoo...        0\n1  10134  @USER Mekanı cennet olsun, saygılar sayın avuk...        0\n2  23457  Kızlar aranızda kas yığını beylere düşenler ol...        0\n3  18401  Biraz ders çalışayım. Tembellik ve uyku düşman...        0\n4  17525  @USER Trezeguet yerine El Sharawy daha iyi olm...        0\n5  11996  @USER Bence de olması gerekiyor. Hatta meslek ...        0\n6  38452  Mutlu gorunumlu ama daima mutsuz olanlar burda...        0\n7  12615  100 liraya tras oldum arkadaşım diyo ki ne kes...        0\n8  13520  @USER @USER @USER Reis bu ülkenin Devlet Başka...        1\n9  45562  Var olan, ancak düşünüldüğü kadarıyla vardır. ...        0\nToplam tweet sayısı: 31277\nKullanılacak bigram sayısı: 47\n        0    1    2    3    4    5    6    7    8    9   ...   37   38   39  \\\n0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n5      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n6      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n7      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n8      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n9      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n10     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n11     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n12     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n13     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n14     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n15     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n16     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n17     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n18     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n19     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n20     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n21     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n22     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n23     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n24     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n25     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n26     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n27     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n28     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n29     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n31247  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31248  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31249  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31250  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31251  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31252  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31253  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31254  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31255  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31256  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n31257  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n31258  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n31259  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31260  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31261  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n31262  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31263  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31264  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31265  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31266  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31267  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31268  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31269  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31270  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31271  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31272  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31273  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31274  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31275  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n31276  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n\n        40   41   42   43   44   45   46  \n0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n5      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n6      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n7      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n8      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n9      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n10     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n11     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n12     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n13     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n14     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n15     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n16     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n17     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n18     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n19     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n20     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n21     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n22     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n23     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n24     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n25     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n26     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n27     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n28     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n29     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n...    ...  ...  ...  ...  ...  ...  ...  \n31247  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31248  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31249  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31250  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31251  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31252  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31253  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31254  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31255  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31256  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n31257  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31258  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31259  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31260  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31261  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31262  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31263  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31264  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31265  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31266  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31267  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31268  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31269  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31270  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31271  0.0  1.0  0.0  1.0  0.0  0.0  0.0  \n31272  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31273  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31274  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31275  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n31276  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[31277 rows x 47 columns]\n   length  mention    0    1    2    3    4    5    6    7  ...   38   39  \\\n0       9        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n1       9        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n2      11        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n3       7        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n4       9        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n5      39        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n6      34        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n7      14        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n8      16        3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n9       8        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n\n    40   41   42   43   44   45   46  label  \n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n5  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n6  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n7  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n8  0.0  0.0  0.0  0.0  0.0  0.0  0.0      1  \n9  0.0  0.0  0.0  0.0  0.0  0.0  0.0      0  \n\n[10 rows x 50 columns]\nLogistic Regression Accuracy: 80.65%\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    readTrainFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda66440d67148d4b538b5c0e8cc9b8c9ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}